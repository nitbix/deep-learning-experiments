backend: !!python/unicode 'theano'
class_name: Sequential
config:
- class_name: Conv2D
  config:
    activation: linear
    activity_regularizer: null
    batch_input_shape: !!python/tuple [null, 3, 32, 32]
    bias_constraint: null
    bias_initializer:
      class_name: VarianceScaling
      config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
    bias_regularizer: null
    data_format: channels_first
    dilation_rate: &id001 !!python/tuple [1, 1]
    dtype: float32
    filters: 16
    kernel_constraint: null
    kernel_initializer:
      class_name: VarianceScaling
      config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
    kernel_regularizer:
      class_name: L1L2
      config: {l1: 0.0, l2: 0.0005000000237487257}
    kernel_size: !!python/tuple [3, 3]
    name: conv2d_1
    padding: same
    strides: !!python/tuple [1, 1]
    trainable: true
    use_bias: false
- class_name: Model
  config:
    input_layers:
    - [input_1, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 16, 32, 32]
        dtype: float32
        name: input_1
        sparse: false
      inbound_nodes: []
      name: input_1
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_1
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_1
          - 0
          - 0
          - {}
      name: batch_normalization_1
    - class_name: Activation
      config: {activation: relu, name: activation_1, trainable: true}
      inbound_nodes:
      - - - batch_normalization_1
          - 0
          - 0
          - {}
      name: activation_1
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_2
        padding: same
        strides: &id002 !!python/tuple [1, 1]
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_1
          - 0
          - 0
          - {}
      name: conv2d_2
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_2
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_2
          - 0
          - 0
          - {}
      name: batch_normalization_2
    - class_name: Activation
      config: {activation: relu, name: activation_2, trainable: true}
      inbound_nodes:
      - - - batch_normalization_2
          - 0
          - 0
          - {}
      name: activation_2
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_3
        padding: same
        strides: &id004 !!python/tuple [1, 1]
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_2
          - 0
          - 0
          - {}
      name: conv2d_3
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: &id009 !!python/tuple [1, 1]
        name: conv2d_4
        padding: same
        strides: *id002
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_1
          - 0
          - 0
          - {}
      name: conv2d_4
    - class_name: Add
      config: {name: add_1, trainable: true}
      inbound_nodes:
      - - - conv2d_3
          - 0
          - 0
          - &id003 {}
        - - conv2d_4
          - 0
          - 0
          - *id003
      name: add_1
    name: model_1
    output_layers:
    - [add_1, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_2, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 160, 32, 32]
        dtype: float32
        name: input_2
        sparse: false
      inbound_nodes: []
      name: input_2
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_3
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_2
          - 0
          - 0
          - {}
      name: batch_normalization_3
    - class_name: Activation
      config: {activation: relu, name: activation_3, trainable: true}
      inbound_nodes:
      - - - batch_normalization_3
          - 0
          - 0
          - {}
      name: activation_3
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_5
        padding: same
        strides: &id006 !!python/tuple [1, 1]
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_3
          - 0
          - 0
          - {}
      name: conv2d_5
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_4
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_5
          - 0
          - 0
          - {}
      name: batch_normalization_4
    - class_name: Activation
      config: {activation: relu, name: activation_4, trainable: true}
      inbound_nodes:
      - - - batch_normalization_4
          - 0
          - 0
          - {}
      name: activation_4
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_6
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_4
          - 0
          - 0
          - {}
      name: conv2d_6
    - class_name: Add
      config: {name: add_2, trainable: true}
      inbound_nodes:
      - - - conv2d_6
          - 0
          - 0
          - &id005 {}
        - - input_2
          - 0
          - 0
          - *id005
      name: add_2
    name: model_2
    output_layers:
    - [add_2, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_3, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 160, 32, 32]
        dtype: float32
        name: input_3
        sparse: false
      inbound_nodes: []
      name: input_3
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_5
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_3
          - 0
          - 0
          - {}
      name: batch_normalization_5
    - class_name: Activation
      config: {activation: relu, name: activation_5, trainable: true}
      inbound_nodes:
      - - - batch_normalization_5
          - 0
          - 0
          - {}
      name: activation_5
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_7
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_5
          - 0
          - 0
          - {}
      name: conv2d_7
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_6
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_7
          - 0
          - 0
          - {}
      name: batch_normalization_6
    - class_name: Activation
      config: {activation: relu, name: activation_6, trainable: true}
      inbound_nodes:
      - - - batch_normalization_6
          - 0
          - 0
          - {}
      name: activation_6
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_8
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_6
          - 0
          - 0
          - {}
      name: conv2d_8
    - class_name: Add
      config: {name: add_3, trainable: true}
      inbound_nodes:
      - - - conv2d_8
          - 0
          - 0
          - &id007 {}
        - - input_3
          - 0
          - 0
          - *id007
      name: add_3
    name: model_3
    output_layers:
    - [add_3, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_4, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 160, 32, 32]
        dtype: float32
        name: input_4
        sparse: false
      inbound_nodes: []
      name: input_4
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_7
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_4
          - 0
          - 0
          - {}
      name: batch_normalization_7
    - class_name: Activation
      config: {activation: relu, name: activation_7, trainable: true}
      inbound_nodes:
      - - - batch_normalization_7
          - 0
          - 0
          - {}
      name: activation_7
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_9
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_7
          - 0
          - 0
          - {}
      name: conv2d_9
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_8
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_9
          - 0
          - 0
          - {}
      name: batch_normalization_8
    - class_name: Activation
      config: {activation: relu, name: activation_8, trainable: true}
      inbound_nodes:
      - - - batch_normalization_8
          - 0
          - 0
          - {}
      name: activation_8
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 160
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_10
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_8
          - 0
          - 0
          - {}
      name: conv2d_10
    - class_name: Add
      config: {name: add_4, trainable: true}
      inbound_nodes:
      - - - conv2d_10
          - 0
          - 0
          - &id008 {}
        - - input_4
          - 0
          - 0
          - *id008
      name: add_4
    name: model_4
    output_layers:
    - [add_4, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_5, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 160, 32, 32]
        dtype: float32
        name: input_5
        sparse: false
      inbound_nodes: []
      name: input_5
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_9
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_5
          - 0
          - 0
          - {}
      name: batch_normalization_9
    - class_name: Activation
      config: {activation: relu, name: activation_9, trainable: true}
      inbound_nodes:
      - - - batch_normalization_9
          - 0
          - 0
          - {}
      name: activation_9
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_11
        padding: same
        strides: &id010 !!python/tuple [2, 2]
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_9
          - 0
          - 0
          - {}
      name: conv2d_11
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_10
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_11
          - 0
          - 0
          - {}
      name: batch_normalization_10
    - class_name: Activation
      config: {activation: relu, name: activation_10, trainable: true}
      inbound_nodes:
      - - - batch_normalization_10
          - 0
          - 0
          - {}
      name: activation_10
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_12
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_10
          - 0
          - 0
          - {}
      name: conv2d_12
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: *id009
        name: conv2d_13
        padding: same
        strides: *id010
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_9
          - 0
          - 0
          - {}
      name: conv2d_13
    - class_name: Add
      config: {name: add_5, trainable: true}
      inbound_nodes:
      - - - conv2d_12
          - 0
          - 0
          - &id011 {}
        - - conv2d_13
          - 0
          - 0
          - *id011
      name: add_5
    name: model_5
    output_layers:
    - [add_5, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_6, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 320, 16, 16]
        dtype: float32
        name: input_6
        sparse: false
      inbound_nodes: []
      name: input_6
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_11
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_6
          - 0
          - 0
          - {}
      name: batch_normalization_11
    - class_name: Activation
      config: {activation: relu, name: activation_11, trainable: true}
      inbound_nodes:
      - - - batch_normalization_11
          - 0
          - 0
          - {}
      name: activation_11
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_14
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_11
          - 0
          - 0
          - {}
      name: conv2d_14
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_12
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_14
          - 0
          - 0
          - {}
      name: batch_normalization_12
    - class_name: Activation
      config: {activation: relu, name: activation_12, trainable: true}
      inbound_nodes:
      - - - batch_normalization_12
          - 0
          - 0
          - {}
      name: activation_12
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_15
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_12
          - 0
          - 0
          - {}
      name: conv2d_15
    - class_name: Add
      config: {name: add_6, trainable: true}
      inbound_nodes:
      - - - conv2d_15
          - 0
          - 0
          - &id012 {}
        - - input_6
          - 0
          - 0
          - *id012
      name: add_6
    name: model_6
    output_layers:
    - [add_6, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_7, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 320, 16, 16]
        dtype: float32
        name: input_7
        sparse: false
      inbound_nodes: []
      name: input_7
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_13
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_7
          - 0
          - 0
          - {}
      name: batch_normalization_13
    - class_name: Activation
      config: {activation: relu, name: activation_13, trainable: true}
      inbound_nodes:
      - - - batch_normalization_13
          - 0
          - 0
          - {}
      name: activation_13
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_16
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_13
          - 0
          - 0
          - {}
      name: conv2d_16
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_14
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_16
          - 0
          - 0
          - {}
      name: batch_normalization_14
    - class_name: Activation
      config: {activation: relu, name: activation_14, trainable: true}
      inbound_nodes:
      - - - batch_normalization_14
          - 0
          - 0
          - {}
      name: activation_14
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_17
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_14
          - 0
          - 0
          - {}
      name: conv2d_17
    - class_name: Add
      config: {name: add_7, trainable: true}
      inbound_nodes:
      - - - conv2d_17
          - 0
          - 0
          - &id013 {}
        - - input_7
          - 0
          - 0
          - *id013
      name: add_7
    name: model_7
    output_layers:
    - [add_7, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_8, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 320, 16, 16]
        dtype: float32
        name: input_8
        sparse: false
      inbound_nodes: []
      name: input_8
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_15
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_8
          - 0
          - 0
          - {}
      name: batch_normalization_15
    - class_name: Activation
      config: {activation: relu, name: activation_15, trainable: true}
      inbound_nodes:
      - - - batch_normalization_15
          - 0
          - 0
          - {}
      name: activation_15
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_18
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_15
          - 0
          - 0
          - {}
      name: conv2d_18
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_16
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_18
          - 0
          - 0
          - {}
      name: batch_normalization_16
    - class_name: Activation
      config: {activation: relu, name: activation_16, trainable: true}
      inbound_nodes:
      - - - batch_normalization_16
          - 0
          - 0
          - {}
      name: activation_16
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 320
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_19
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_16
          - 0
          - 0
          - {}
      name: conv2d_19
    - class_name: Add
      config: {name: add_8, trainable: true}
      inbound_nodes:
      - - - conv2d_19
          - 0
          - 0
          - &id014 {}
        - - input_8
          - 0
          - 0
          - *id014
      name: add_8
    name: model_8
    output_layers:
    - [add_8, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_9, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 320, 16, 16]
        dtype: float32
        name: input_9
        sparse: false
      inbound_nodes: []
      name: input_9
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_17
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_9
          - 0
          - 0
          - {}
      name: batch_normalization_17
    - class_name: Activation
      config: {activation: relu, name: activation_17, trainable: true}
      inbound_nodes:
      - - - batch_normalization_17
          - 0
          - 0
          - {}
      name: activation_17
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_20
        padding: same
        strides: &id015 !!python/tuple [2, 2]
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_17
          - 0
          - 0
          - {}
      name: conv2d_20
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_18
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_20
          - 0
          - 0
          - {}
      name: batch_normalization_18
    - class_name: Activation
      config: {activation: relu, name: activation_18, trainable: true}
      inbound_nodes:
      - - - batch_normalization_18
          - 0
          - 0
          - {}
      name: activation_18
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_21
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_18
          - 0
          - 0
          - {}
      name: conv2d_21
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: *id009
        name: conv2d_22
        padding: same
        strides: *id015
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_17
          - 0
          - 0
          - {}
      name: conv2d_22
    - class_name: Add
      config: {name: add_9, trainable: true}
      inbound_nodes:
      - - - conv2d_21
          - 0
          - 0
          - &id016 {}
        - - conv2d_22
          - 0
          - 0
          - *id016
      name: add_9
    name: model_9
    output_layers:
    - [add_9, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_10, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 640, 8, 8]
        dtype: float32
        name: input_10
        sparse: false
      inbound_nodes: []
      name: input_10
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_19
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_10
          - 0
          - 0
          - {}
      name: batch_normalization_19
    - class_name: Activation
      config: {activation: relu, name: activation_19, trainable: true}
      inbound_nodes:
      - - - batch_normalization_19
          - 0
          - 0
          - {}
      name: activation_19
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_23
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_19
          - 0
          - 0
          - {}
      name: conv2d_23
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_20
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_23
          - 0
          - 0
          - {}
      name: batch_normalization_20
    - class_name: Activation
      config: {activation: relu, name: activation_20, trainable: true}
      inbound_nodes:
      - - - batch_normalization_20
          - 0
          - 0
          - {}
      name: activation_20
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_24
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_20
          - 0
          - 0
          - {}
      name: conv2d_24
    - class_name: Add
      config: {name: add_10, trainable: true}
      inbound_nodes:
      - - - conv2d_24
          - 0
          - 0
          - &id017 {}
        - - input_10
          - 0
          - 0
          - *id017
      name: add_10
    name: model_10
    output_layers:
    - [add_10, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_11, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 640, 8, 8]
        dtype: float32
        name: input_11
        sparse: false
      inbound_nodes: []
      name: input_11
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_21
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_11
          - 0
          - 0
          - {}
      name: batch_normalization_21
    - class_name: Activation
      config: {activation: relu, name: activation_21, trainable: true}
      inbound_nodes:
      - - - batch_normalization_21
          - 0
          - 0
          - {}
      name: activation_21
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_25
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_21
          - 0
          - 0
          - {}
      name: conv2d_25
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_22
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_25
          - 0
          - 0
          - {}
      name: batch_normalization_22
    - class_name: Activation
      config: {activation: relu, name: activation_22, trainable: true}
      inbound_nodes:
      - - - batch_normalization_22
          - 0
          - 0
          - {}
      name: activation_22
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_26
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_22
          - 0
          - 0
          - {}
      name: conv2d_26
    - class_name: Add
      config: {name: add_11, trainable: true}
      inbound_nodes:
      - - - conv2d_26
          - 0
          - 0
          - &id018 {}
        - - input_11
          - 0
          - 0
          - *id018
      name: add_11
    name: model_11
    output_layers:
    - [add_11, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [input_12, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 640, 8, 8]
        dtype: float32
        name: input_12
        sparse: false
      inbound_nodes: []
      name: input_12
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_23
        scale: true
        trainable: true
      inbound_nodes:
      - - - input_12
          - 0
          - 0
          - {}
      name: batch_normalization_23
    - class_name: Activation
      config: {activation: relu, name: activation_23, trainable: true}
      inbound_nodes:
      - - - batch_normalization_23
          - 0
          - 0
          - {}
      name: activation_23
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_27
        padding: same
        strides: *id006
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_23
          - 0
          - 0
          - {}
      name: conv2d_27
    - class_name: BatchNormalization
      config:
        axis: 1
        beta_constraint: null
        beta_initializer:
          class_name: Zeros
          config: {}
        beta_regularizer: null
        center: true
        epsilon: 0.001
        gamma_constraint: null
        gamma_initializer:
          class_name: Ones
          config: {}
        gamma_regularizer: null
        momentum: 0.99
        moving_mean_initializer:
          class_name: Zeros
          config: {}
        moving_variance_initializer:
          class_name: Ones
          config: {}
        name: batch_normalization_24
        scale: true
        trainable: true
      inbound_nodes:
      - - - conv2d_27
          - 0
          - 0
          - {}
      name: batch_normalization_24
    - class_name: Activation
      config: {activation: relu, name: activation_24, trainable: true}
      inbound_nodes:
      - - - batch_normalization_24
          - 0
          - 0
          - {}
      name: activation_24
    - class_name: Conv2D
      config:
        activation: linear
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        bias_regularizer: null
        data_format: channels_first
        dilation_rate: *id001
        filters: 640
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
        kernel_regularizer:
          class_name: L1L2
          config: {l1: 0.0, l2: 0.0005000000237487257}
        kernel_size: !!python/tuple [3, 3]
        name: conv2d_28
        padding: same
        strides: *id004
        trainable: true
        use_bias: false
      inbound_nodes:
      - - - activation_24
          - 0
          - 0
          - {}
      name: conv2d_28
    - class_name: Add
      config: {name: add_12, trainable: true}
      inbound_nodes:
      - - - conv2d_28
          - 0
          - 0
          - &id019 {}
        - - input_12
          - 0
          - 0
          - *id019
      name: add_12
    name: model_12
    output_layers:
    - [add_12, 0, 0]
- class_name: BatchNormalization
  config:
    axis: 1
    beta_constraint: null
    beta_initializer:
      class_name: Zeros
      config: {}
    beta_regularizer: null
    center: true
    epsilon: 0.001
    gamma_constraint: null
    gamma_initializer:
      class_name: Ones
      config: {}
    gamma_regularizer: null
    momentum: 0.99
    moving_mean_initializer:
      class_name: Zeros
      config: {}
    moving_variance_initializer:
      class_name: Ones
      config: {}
    name: batch_normalization_25
    scale: true
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_25, trainable: true}
- class_name: AveragePooling2D
  config:
    data_format: channels_first
    name: average_pooling2d_1
    padding: same
    pool_size: !!python/tuple [8, 8]
    strides: !!python/tuple [1, 1]
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config:
    activation: softmax
    activity_regularizer: null
    bias_constraint: null
    bias_initializer:
      class_name: VarianceScaling
      config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
    bias_regularizer: null
    kernel_constraint: null
    kernel_initializer:
      class_name: VarianceScaling
      config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
    kernel_regularizer:
      class_name: L1L2
      config: {l1: 0.0, l2: 0.0005000000237487257}
    name: dense_1
    trainable: true
    units: 10
    use_bias: false
keras_version: 2.0.3

