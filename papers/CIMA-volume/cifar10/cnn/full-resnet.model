class_name: Sequential
config:
- class_name: ZeroPadding2D
  config:
    batch_input_shape: !!python/tuple [null, 3, 32, 32]
    input_dtype: float32
    name: zeropadding2d_1
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_1
    nb_col: 3
    nb_filter: 96
    nb_row: 3
    subsample: &id001 !!python/tuple [1, 1]
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_1, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_1, trainable: true}
- class_name: ZeroPadding2D
  config:
    name: zeropadding2d_2
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_2
    nb_col: 3
    nb_filter: 96
    nb_row: 3
    subsample: *id001
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_2, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_2, trainable: true}
- class_name: ZeroPadding2D
  config:
    name: zeropadding2d_3
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_3
    nb_col: 3
    nb_filter: 96
    nb_row: 3
    subsample: !!python/tuple [2, 2]
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_3, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_3, trainable: true}
- class_name: MaxPooling2D
  config:
    border_mode: same
    dim_ordering: th
    name: maxpooling2d_1
    pool_size: !!python/tuple [2, 2]
    strides: !!python/tuple [2, 2]
    trainable: true
- class_name: Dropout
  config: {name: dropout_1, p: 0.5, trainable: true}
- class_name: ZeroPadding2D
  config:
    name: zeropadding2d_4
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_4
    nb_col: 3
    nb_filter: 192
    nb_row: 3
    subsample: *id001
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_4, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_4, trainable: true}
- class_name: ZeroPadding2D
  config:
    name: zeropadding2d_5
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_5
    nb_col: 3
    nb_filter: 192
    nb_row: 3
    subsample: *id001
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_5, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_5, trainable: true}
- class_name: ZeroPadding2D
  config:
    name: zeropadding2d_6
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_6
    nb_col: 3
    nb_filter: 192
    nb_row: 3
    subsample: !!python/tuple [2, 2]
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_6, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_6, trainable: true}
- class_name: MaxPooling2D
  config:
    border_mode: same
    dim_ordering: th
    name: maxpooling2d_2
    pool_size: !!python/tuple [2, 2]
    strides: !!python/tuple [2, 2]
    trainable: true
- class_name: Dropout
  config: {name: dropout_2, p: 0.5, trainable: true}
- class_name: ZeroPadding2D
  config:
    name: zeropadding2d_7
    padding: !!python/tuple [1, 1]
    trainable: true
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_7
    nb_col: 3
    nb_filter: 192
    nb_row: 3
    subsample: *id001
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_7, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_7, trainable: true}
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_8
    nb_col: 1
    nb_filter: 192
    nb_row: 1
    subsample: *id001
    trainable: true
- class_name: Activation
  config: {activation: relu, name: activation_8, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_8, trainable: true}
- class_name: Convolution2D
  config:
    W_constraint: null
    W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
    bias: true
    border_mode: same
    dim_ordering: th
    init: glorot_uniform
    name: convolution2d_9
    nb_col: 1
    nb_filter: 10
    nb_row: 1
    subsample: *id001
    trainable: true
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_0, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 10, 6, 6]
        input_dtype: float32
        name: Input_BRN_0
        sparse: false
      inbound_nodes: []
      name: Input_BRN_0
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-0-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_0, 0, 0]
      name: BRN-incremental-0-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-0-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-0-0, 0, 0]
      name: BRN-incremental-0-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-0-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: &id002 !!python/tuple [1, 1]
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-0-1, 0, 0]
      name: BRN-incremental-0-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-0-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-0-2, 0, 0]
      name: BRN-incremental-0-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-0-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-0-3, 0, 0]
      name: BRN-incremental-0-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-0-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: &id003 !!python/tuple [1, 1]
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-0-4, 0, 0]
      name: BRN-incremental-0-5
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: null
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: null
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: shortcut_BRN_0
        nb_col: 1
        nb_filter: 192
        nb_row: 1
        subsample: !!python/tuple [1, 1]
        trainable: true
      inbound_nodes:
      - - [Input_BRN_0, 0, 0]
      name: shortcut_BRN_0
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_0,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-0-5, 0, 0]
        - [shortcut_BRN_0, 0, 0]
      name: merge_BRN_0
    name: Model_BRN_0
    output_layers:
    - [merge_BRN_0, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_1, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_1
        sparse: false
      inbound_nodes: []
      name: Input_BRN_1
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-1-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_1, 0, 0]
      name: BRN-incremental-1-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-1-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-1-0, 0, 0]
      name: BRN-incremental-1-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-1-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-1-1, 0, 0]
      name: BRN-incremental-1-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-1-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-1-2, 0, 0]
      name: BRN-incremental-1-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-1-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-1-3, 0, 0]
      name: BRN-incremental-1-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-1-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-1-4, 0, 0]
      name: BRN-incremental-1-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_1,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-1-5, 0, 0]
        - [Input_BRN_1, 0, 0]
      name: merge_BRN_1
    name: Model_BRN_1
    output_layers:
    - [merge_BRN_1, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_2, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_2
        sparse: false
      inbound_nodes: []
      name: Input_BRN_2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-2-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_2, 0, 0]
      name: BRN-incremental-2-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-2-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-2-0, 0, 0]
      name: BRN-incremental-2-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-2-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-2-1, 0, 0]
      name: BRN-incremental-2-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-2-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-2-2, 0, 0]
      name: BRN-incremental-2-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-2-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-2-3, 0, 0]
      name: BRN-incremental-2-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-2-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-2-4, 0, 0]
      name: BRN-incremental-2-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_2,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-2-5, 0, 0]
        - [Input_BRN_2, 0, 0]
      name: merge_BRN_2
    name: Model_BRN_2
    output_layers:
    - [merge_BRN_2, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_3, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_3
        sparse: false
      inbound_nodes: []
      name: Input_BRN_3
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-3-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_3, 0, 0]
      name: BRN-incremental-3-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-3-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-3-0, 0, 0]
      name: BRN-incremental-3-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-3-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-3-1, 0, 0]
      name: BRN-incremental-3-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-3-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-3-2, 0, 0]
      name: BRN-incremental-3-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-3-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-3-3, 0, 0]
      name: BRN-incremental-3-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-3-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-3-4, 0, 0]
      name: BRN-incremental-3-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_3,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-3-5, 0, 0]
        - [Input_BRN_3, 0, 0]
      name: merge_BRN_3
    name: Model_BRN_3
    output_layers:
    - [merge_BRN_3, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_4, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_4
        sparse: false
      inbound_nodes: []
      name: Input_BRN_4
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-4-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_4, 0, 0]
      name: BRN-incremental-4-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-4-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-4-0, 0, 0]
      name: BRN-incremental-4-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-4-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-4-1, 0, 0]
      name: BRN-incremental-4-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-4-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-4-2, 0, 0]
      name: BRN-incremental-4-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-4-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-4-3, 0, 0]
      name: BRN-incremental-4-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-4-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-4-4, 0, 0]
      name: BRN-incremental-4-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_4,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-4-5, 0, 0]
        - [Input_BRN_4, 0, 0]
      name: merge_BRN_4
    name: Model_BRN_4
    output_layers:
    - [merge_BRN_4, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_5, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_5
        sparse: false
      inbound_nodes: []
      name: Input_BRN_5
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-5-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_5, 0, 0]
      name: BRN-incremental-5-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-5-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-5-0, 0, 0]
      name: BRN-incremental-5-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-5-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-5-1, 0, 0]
      name: BRN-incremental-5-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-5-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-5-2, 0, 0]
      name: BRN-incremental-5-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-5-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-5-3, 0, 0]
      name: BRN-incremental-5-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-5-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-5-4, 0, 0]
      name: BRN-incremental-5-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_5,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-5-5, 0, 0]
        - [Input_BRN_5, 0, 0]
      name: merge_BRN_5
    name: Model_BRN_5
    output_layers:
    - [merge_BRN_5, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_6, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_6
        sparse: false
      inbound_nodes: []
      name: Input_BRN_6
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-6-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_6, 0, 0]
      name: BRN-incremental-6-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-6-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-6-0, 0, 0]
      name: BRN-incremental-6-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-6-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-6-1, 0, 0]
      name: BRN-incremental-6-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-6-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-6-2, 0, 0]
      name: BRN-incremental-6-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-6-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-6-3, 0, 0]
      name: BRN-incremental-6-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-6-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-6-4, 0, 0]
      name: BRN-incremental-6-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_6,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-6-5, 0, 0]
        - [Input_BRN_6, 0, 0]
      name: merge_BRN_6
    name: Model_BRN_6
    output_layers:
    - [merge_BRN_6, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_7, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_7
        sparse: false
      inbound_nodes: []
      name: Input_BRN_7
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-7-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_7, 0, 0]
      name: BRN-incremental-7-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-7-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-7-0, 0, 0]
      name: BRN-incremental-7-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-7-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-7-1, 0, 0]
      name: BRN-incremental-7-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-7-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-7-2, 0, 0]
      name: BRN-incremental-7-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-7-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-7-3, 0, 0]
      name: BRN-incremental-7-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-7-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-7-4, 0, 0]
      name: BRN-incremental-7-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_7,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-7-5, 0, 0]
        - [Input_BRN_7, 0, 0]
      name: merge_BRN_7
    name: Model_BRN_7
    output_layers:
    - [merge_BRN_7, 0, 0]
- class_name: Model
  config:
    input_layers:
    - [Input_BRN_8, 0, 0]
    layers:
    - class_name: InputLayer
      config:
        batch_input_shape: !!python/tuple [null, 192, 6, 6]
        input_dtype: float32
        name: Input_BRN_8
        sparse: false
      inbound_nodes: []
      name: Input_BRN_8
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-8-0, trainable: true}
      inbound_nodes:
      - - [Input_BRN_8, 0, 0]
      name: BRN-incremental-8-0
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-8-1, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-8-0, 0, 0]
      name: BRN-incremental-8-1
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-8-2
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id002
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-8-1, 0, 0]
      name: BRN-incremental-8-2
    - class_name: BatchNormalization
      config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
        mode: 2, momentum: 0.99, name: BRN-incremental-8-3, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-8-2, 0, 0]
      name: BRN-incremental-8-3
    - class_name: Activation
      config: {activation: relu, name: BRN-incremental-8-4, trainable: true}
      inbound_nodes:
      - - [BRN-incremental-8-3, 0, 0]
      name: BRN-incremental-8-4
    - class_name: Convolution2D
      config:
        W_constraint: null
        W_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        activation: linear
        activity_regularizer: null
        b_constraint: null
        b_regularizer: {l1: 0.0, l2: 9.999999747378752e-05, name: WeightRegularizer}
        bias: true
        border_mode: same
        dim_ordering: th
        init: he_normal
        name: BRN-incremental-8-5
        nb_col: 3
        nb_filter: 192
        nb_row: 3
        subsample: *id003
        trainable: true
      inbound_nodes:
      - - [BRN-incremental-8-4, 0, 0]
      name: BRN-incremental-8-5
    - class_name: Merge
      config: {concat_axis: -1, dot_axes: -1, mode: sum, mode_type: raw, name: merge_BRN_8,
        output_shape: null, output_shape_type: raw}
      inbound_nodes:
      - - [BRN-incremental-8-5, 0, 0]
        - [Input_BRN_8, 0, 0]
      name: merge_BRN_8
    name: Model_BRN_8
    output_layers:
    - [merge_BRN_8, 0, 0]
- class_name: Activation
  config: {activation: relu, name: activation_9, trainable: true}
- class_name: BatchNormalization
  config: {axis: 1, beta_regularizer: null, epsilon: 1.0e-05, gamma_regularizer: null,
    mode: 2, momentum: 0.99, name: batchnormalization_9, trainable: true}
- class_name: AveragePooling2D
  config:
    border_mode: same
    dim_ordering: th
    name: averagepooling2d_1
    pool_size: &id004 !!python/tuple [8, 8]
    strides: *id004
    trainable: true
- class_name: Flatten
  config: {name: flatten_1, trainable: true}
- class_name: Dense
  config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
    b_constraint: null, b_regularizer: null, bias: true, init: he_normal, input_dim: null,
    name: dense_2, output_dim: 10, trainable: true}
- class_name: Activation
  config: {activation: softmax, name: activation_10, trainable: true}
keras_version: 1.1.0
